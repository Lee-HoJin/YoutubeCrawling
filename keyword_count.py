import pandas as pd
import re
from collections import Counter

# CSV íŒŒì¼ ì½ê¸°
df = pd.read_csv('patagonia_youtube_descriptions.csv')
print(f"ğŸ“Š ì´ {len(df)}ê°œ ì˜ìƒ ë¶„ì„ ì¤‘...")

# ë°©ë²• 1: ê¸°ë³¸ì ì¸ ì†Œë¬¸ì ë³€í™˜ ë°©ë²•
print("\n" + "="*50)
print("ğŸ” ë°©ë²• 1: ê¸°ë³¸ ì†Œë¬¸ì ë³€í™˜")
print("="*50)

# ëª¨ë“  ì„¤ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ í•©ì¹˜ê¸°
all_descriptions_lower = ' '.join(df['description'].fillna('').astype(str)).lower()

# í‚¤ì›Œë“œë„ ì†Œë¬¸ìë¡œ í†µì¼
keywords = ['environment', 'carbon', 'social', 'diversity', 'sustainability', 'green', 'eco', 'esg']

print(f"ğŸ·ï¸  í‚¤ì›Œë“œ ì¶œí˜„ ë¹ˆë„ (ê¸°ë³¸ ë§¤ì¹­):")
for keyword in keywords:
    count = all_descriptions_lower.count(keyword)
    if count > 0:
        print(f"   - '{keyword}': {count}íšŒ")

# ë°©ë²• 2: ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•œ ë‹¨ì–´ ê²½ê³„ ë§¤ì¹­ (ë” ì •í™•í•¨)
print("\n" + "="*50)
print("ğŸ” ë°©ë²• 2: ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ (ì¶”ì²œ)")
print("="*50)

def count_word_exact(text, word):
    """ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì •í™•í•œ ì¹´ìš´íŒ…"""
    # \bëŠ” ë‹¨ì–´ ê²½ê³„ë¥¼ ì˜ë¯¸ (ì˜ˆ: "carbon"ì´ "carbonate"ì— í¬í•¨ë˜ì§€ ì•Šë„ë¡)
    pattern = r'\b' + re.escape(word.lower()) + r'\b'
    return len(re.findall(pattern, text.lower()))

print(f"ğŸ·ï¸  í‚¤ì›Œë“œ ì¶œí˜„ ë¹ˆë„ (ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­):")
keyword_counts = {}
for keyword in keywords:
    count = count_word_exact(all_descriptions_lower, keyword)
    keyword_counts[keyword] = count
    if count > 0:
        print(f"   - '{keyword}': {count}íšŒ")

# ë°©ë²• 3: ë³µìˆ˜í˜•/ë³€í˜•ë„ í•¨ê»˜ ê³ ë ¤
print("\n" + "="*50)
print("ğŸ” ë°©ë²• 3: ë³µìˆ˜í˜•/ë³€í˜• í¬í•¨ ë§¤ì¹­")
print("="*50)

# í‚¤ì›Œë“œì™€ ê·¸ ë³€í˜•ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ì •ì˜
keyword_groups = {
    'environment': ['environment', 'environmental', 'environments'],
    'carbon': ['carbon', 'carbons', 'carbon-neutral', 'carbon-free'],
    'social': ['social', 'socially', 'society'],
    'diversity': ['diversity', 'diverse', 'inclusion', 'inclusive'],
    'sustainability': ['sustainability', 'sustainable', 'sustain'],
    'green': ['green', 'eco-friendly', 'eco'],
    'climate': ['climate', 'global warming', 'warming']
}

def count_keyword_group(text, word_list):
    """í‚¤ì›Œë“œ ê·¸ë£¹ì˜ ëª¨ë“  ë³€í˜•ì„ ì¹´ìš´íŒ…"""
    total_count = 0
    details = {}
    for word in word_list:
        count = count_word_exact(text, word)
        if count > 0:
            details[word] = count
        total_count += count
    return total_count, details

print(f"ğŸ·ï¸  í‚¤ì›Œë“œ ê·¸ë£¹ë³„ ì¶œí˜„ ë¹ˆë„:")
group_results = {}
for group_name, word_list in keyword_groups.items():
    total_count, details = count_keyword_group(all_descriptions_lower, word_list)
    group_results[group_name] = {'total': total_count, 'details': details}
    
    if total_count > 0:
        print(f"   ğŸ“‚ '{group_name}': {total_count}íšŒ")
        for word, count in details.items():
            print(f"      â”” '{word}': {count}íšŒ")

# ë°©ë²• 4: ì˜ìƒë³„ í‚¤ì›Œë“œ ë¶„ì„
print("\n" + "="*50)
print("ğŸ” ë°©ë²• 4: ì˜ìƒë³„ í‚¤ì›Œë“œ ë¶„ì„")
print("="*50)

def analyze_video_keywords(df, keywords):
    """ê° ì˜ìƒë³„ë¡œ í‚¤ì›Œë“œ ì¶œí˜„ ë¶„ì„"""
    video_keyword_data = []
    
    for idx, row in df.iterrows():
        description = str(row['description']).lower() if pd.notna(row['description']) else ''
        video_data = {
            'video_id': row['video_id'],
            'title': row['title'][:50] + '...' if len(str(row['title'])) > 50 else row['title'],
            'total_keywords': 0
        }
        
        # ê° í‚¤ì›Œë“œ ì¹´ìš´íŒ…
        for keyword in keywords:
            count = count_word_exact(description, keyword)
            video_data[keyword] = count
            video_data['total_keywords'] += count
        
        video_keyword_data.append(video_data)
    
    return pd.DataFrame(video_keyword_data)

# ì˜ìƒë³„ ë¶„ì„ ì‹¤í–‰
video_analysis = analyze_video_keywords(df, keywords)

# í‚¤ì›Œë“œê°€ ë§ì´ í¬í•¨ëœ ì˜ìƒ ìƒìœ„ 10ê°œ
top_videos = video_analysis.nlargest(10, 'total_keywords')

print(f"ğŸ¬ í‚¤ì›Œë“œê°€ ë§ì´ í¬í•¨ëœ ì˜ìƒ TOP 10:")
for idx, video in top_videos.iterrows():
    if video['total_keywords'] > 0:
        print(f"   {video['total_keywords']}ê°œ - {video['title']}")

# ë°©ë²• 5: ì „ì²´ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸
print("\n" + "="*50)
print("ğŸ“ˆ ì „ì²´ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸")
print("="*50)

total_videos = len(df)
videos_with_keywords = len(video_analysis[video_analysis['total_keywords'] > 0])
keyword_videos_percentage = (videos_with_keywords / total_videos) * 100

print(f"ğŸ“Š ì „ì²´ í†µê³„:")
print(f"   - ì´ ì˜ìƒ ìˆ˜: {total_videos}ê°œ")
print(f"   - í‚¤ì›Œë“œ í¬í•¨ ì˜ìƒ: {videos_with_keywords}ê°œ")
print(f"   - í‚¤ì›Œë“œ í¬í•¨ ë¹„ìœ¨: {keyword_videos_percentage:.1f}%")

# ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” í‚¤ì›Œë“œ
most_common_keywords = []
for keyword in keywords:
    total_count = video_analysis[keyword].sum()
    if total_count > 0:
        most_common_keywords.append((keyword, total_count))

most_common_keywords.sort(key=lambda x: x[1], reverse=True)

print(f"\nğŸ† ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” í‚¤ì›Œë“œ:")
for keyword, count in most_common_keywords:
    print(f"   - '{keyword}': {count}íšŒ")

# í‚¤ì›Œë“œë³„ ì˜ìƒ ë¶„í¬
print(f"\nğŸ“ˆ í‚¤ì›Œë“œë³„ ì˜ìƒ ë¶„í¬:")
for keyword in keywords:
    videos_with_keyword = len(video_analysis[video_analysis[keyword] > 0])
    if videos_with_keyword > 0:
        percentage = (videos_with_keyword / total_videos) * 100
        print(f"   - '{keyword}': {videos_with_keyword}ê°œ ì˜ìƒ ({percentage:.1f}%)")

# ì„ íƒì ìœ¼ë¡œ ìƒì„¸ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
save_detailed_results = input("\nğŸ’¾ ìƒì„¸ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()

if save_detailed_results == 'y':
    # ì˜ìƒë³„ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥
    output_filename = 'nike_keyword_analysis.csv'
    video_analysis.to_csv(output_filename, index=False, encoding='utf-8-sig')
    print(f"âœ… ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_filename}")
    
    # í‚¤ì›Œë“œ í†µê³„ ìš”ì•½ ì €ì¥
    summary_data = []
    for keyword in keywords:
        total_count = video_analysis[keyword].sum()
        videos_count = len(video_analysis[video_analysis[keyword] > 0])
        summary_data.append({
            'keyword': keyword,
            'total_mentions': total_count,
            'videos_with_keyword': videos_count,
            'percentage_of_videos': (videos_count / total_videos) * 100
        })
    
    summary_df = pd.DataFrame(summary_data)
    summary_filename = 'nike_keyword_summary.csv'
    summary_df.to_csv(summary_filename, index=False, encoding='utf-8-sig')
    print(f"âœ… í‚¤ì›Œë“œ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {summary_filename}")

print(f"\nğŸ‰ í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ!")

"""
ê°œì„ ëœ ì ë“¤:
1. âœ… ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì œê±°
2. âœ… ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ ë°©ì§€)
3. âœ… ë³µìˆ˜í˜•/ë³€í˜• í‚¤ì›Œë“œë„ í•¨ê»˜ ê³ ë ¤
4. âœ… ì˜ìƒë³„ í‚¤ì›Œë“œ ë¶„ì„
5. âœ… ì „ì²´ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ
6. âœ… ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ ê°€ëŠ¥

ì‚¬ìš© ë°©ë²•:
1. ìœ„ ì½”ë“œë¥¼ keyword_analysis.pyë¡œ ì €ì¥
2. nike_youtube_descriptions.csv íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìœ„ì¹˜
3. python keyword_analysis.py ì‹¤í–‰
"""